{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Fun with convolutional networks\n",
    "> <span style=\"color:gray\">\n",
    "Original [Theano/Lasagne tutorial](https://github.com/DeepLearningDTU/nvidia_deep_learning_summercamp_2016/blob/master/lab1/lab1_FFN.ipynb) by \n",
    "Lars Maaløe ([larsmaaloee](https://github.com/larsmaaloee)),\n",
    "Søren Kaae Sønderby ([skaae](https://github.com/skaae)), and \n",
    "Casper Sønderby ([casperkaae](https://github.com/casperkaae)). \n",
    "Converted to TensorFlow by \n",
    "Alexander R. Johansen ([alrojo](https://github.com/alrojo)), \n",
    "and updated by \n",
    "Toke Faurby ([faur](https://github.com/Faur)).\n",
    "</span>\n",
    "\n",
    "\n",
    "This notebook demonstrates one of the many cool applications of convolutional neural networks.\n",
    "We will work with an augmented version of the MNIST data set.\n",
    "In the data the each mnist digit (20x20 pixels) has been placed randomly in a 60x60 canvas.\n",
    "To make the task harder each canvas has then been cluttered with small pieces of digits.\n",
    "In this task it is helpful for a network if it can focus only on the digit and ignore the rest.\n",
    "\n",
    "\n",
    "The ``TransformerLayer`` lets us do this.\n",
    "The transformer layer learns an affine transformation which lets the network zoom, rotate and skew.\n",
    "If you are interested you should [read the paper](https://arxiv.org/abs/1506.02025), but the main idea is that you can let a small convolutional network determine the parameters of the affine transformation.\n",
    "You then apply the affine transformation to the input data.\n",
    "Usually this also involves downsampling which forces the model to zoom in on the relevant parts of the data. \n",
    "After the affine transformation we can use a larger conv net to do the classification. \n",
    "This is possible because you can backprop through a an affine transformation if you use bilinear interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "If you don't already have the data uncomment and run the line below.\n",
    "The `!` makes the command run as if it was typed into the terminal.\n",
    "If this doesn't work download it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !wget -N https://s3.amazonaws.com/lasagne/recipes/datasets/mnist_cluttered_60x60_6distortions.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mnist_cluttered import load_data\n",
    "\n",
    "DIM = 60\n",
    "\n",
    "data = load_data()\n",
    "idx = 0\n",
    "canvas = np.zeros((DIM*10, 10*DIM))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        canvas[i*DIM:(i+1)*DIM, j*DIM:(j+1)*DIM] = data['X_train'][idx].reshape((DIM, DIM))\n",
    "        idx += 1\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(canvas, cmap='gray')\n",
    "plt.title('Cluttered handwritten digits')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependancies and supporting functions\n",
    "Loading dependancies and supporting functions by running the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "np.random.seed(123)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('.', '..')) \n",
    "import utils \n",
    "from spatial_transformer import transformer\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DIM = 60\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, convolution2d, flatten, max_pool2d\n",
    "pool = max_pool2d\n",
    "conv = convolution2d\n",
    "dense = fully_connected\n",
    "from tensorflow.python.ops.nn import relu, softmax\n",
    "from tensorflow.python.framework.ops import reset_default_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We use a model where the localization network is a two layer convolution network which operates directly on the image input. The output from the localization network is a 6 dimensional vector specifying the parameters in the affine transformation.\n",
    "\n",
    "If the output from the localization networks is \n",
    "```\n",
    "|t1, t2, t3|\n",
    "|t4, t5, t6|\n",
    "```\n",
    "then \n",
    "* t1 and t5 determines zoom, \n",
    "* t2 and t4 determines skewness, and \n",
    "* t3 and t6 move the center position. \n",
    "\n",
    "We set up the transformer layer to initially do the identity transform.\n",
    "By setting the initial values of the bias vector to \n",
    "```\n",
    "|1, 0, 0|\n",
    "|0, 1, 0|\n",
    "```\n",
    "and the final W of the localization network to all zeros we ensure that in the beginning of training the network works as a pooling layer. \n",
    "\n",
    "\n",
    "The output of the localization layer feeds into the transformer layer which applies the transformation to the image input.\n",
    "In our setup the transformer layer downsamples the input by a factor 3.\n",
    "\n",
    "Finally a 2 layer convolution layer and 2 fully connected layers calculates the output probabilities.\n",
    "\n",
    "\n",
    "### The model\n",
    "![](images/transformer_network.png)\n",
    "\n",
    "Notice that the tranformer network is both given the matrix calculated by the localization layer and the original input image. The flow of the data is thus actually:\n",
    "```\n",
    "Input -> localization_network -> TransformerLayer -> output_network -> predictions\n",
    "   |                                |\n",
    "   >--------------------------------^\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def build_model(x_pl, input_width, input_height, output_dim,\n",
    "                batch_size=BATCH_SIZE):\n",
    "    \n",
    "    # Setting up placeholder, this is where your data enters the graph!\n",
    "    l_reshape = tf.transpose(x_pl, [0, 2, 3, 1]) # TensorFlow uses [batch_size, height, widht, depth]\n",
    "\n",
    "    # make distributed representation of input image for localization network\n",
    "    loc_l1 = pool(l_reshape, kernel_size=[2, 2], scope=\"localization_l1\")\n",
    "    loc_l2 = conv(loc_l1, num_outputs=8, kernel_size=[5, 5], stride=[1, 1], padding=\"SAME\", scope=\"localization_l2\")\n",
    "    loc_l3 = pool(loc_l2, kernel_size=[2, 2], scope=\"localization_l3\")\n",
    "    loc_l4 = conv(loc_l3, num_outputs=8, kernel_size=[5, 5], stride=[1, 1], padding=\"SAME\", scope=\"localization_l4\")\n",
    "    loc_l4_flatten = flatten(loc_l4, scope=\"localization_l4-flatten\")\n",
    "    loc_l5 = dense(loc_l4_flatten, num_outputs=50, activation_fn=relu, scope=\"localization_l5\")\n",
    "    \n",
    "    # set up weights for transformation (notice we always need 6 output neurons)\n",
    "    with tf.name_scope(\"localization\"):\n",
    "        W_loc_out = tf.get_variable(\"localization_loc-out\", [50, 6], initializer=tf.constant_initializer(0.0))\n",
    "        initial = np.array([[1, 0, 0], [0, 1, 0]])\n",
    "        initial = initial.astype('float32')\n",
    "        initial = initial.flatten()\n",
    "        b_loc_out = tf.Variable(initial_value=initial, name='b-loc-out')\n",
    "        loc_out = tf.matmul(loc_l5, W_loc_out) + b_loc_out\n",
    "\n",
    "    # spatial transformer\n",
    "    l_trans1 = transformer(l_reshape, loc_out, out_size=(DIM//3, DIM//3))\n",
    "    l_trans1.set_shape([None, DIM//3, DIM//3, 1])\n",
    "    l_trans1_valid = tf.transpose(l_trans1, [0, 2, 3, 1]) # Back into NCHW for validation\n",
    "\n",
    "    print( \"Transformer network output shape: \", l_trans1.get_shape())\n",
    "\n",
    "    # classification network\n",
    "    class_l1 = conv(l_trans1, num_outputs=16, kernel_size=[3, 3], scope=\"classification_l1\")\n",
    "    class_l2 = pool(class_l1, kernel_size=[2, 2], scope=\"classification_l2\")\n",
    "    class_l3 = conv(class_l2, num_outputs=16, kernel_size=[3, 3], scope=\"classification_l3\")\n",
    "    class_l4 = pool(class_l3, kernel_size=[2, 2], scope=\"classification_l4\")\n",
    "    class_l4_flatten = flatten(class_l4, scope=\"classification_l4-flatten\")\n",
    "    class_l5 = dense(class_l4_flatten, num_outputs=256, activation_fn=relu, scope=\"classification_l5\")\n",
    "    l_out = dense(class_l5, num_outputs=output_dim, activation_fn=softmax, scope=\"classification_l-out\")\n",
    "\n",
    "    return l_out, l_trans1_valid\n",
    "\n",
    "x_pl = tf.placeholder(tf.float32, [None, 1, DIM, DIM], name=\"input\")\n",
    "model, l_transform = build_model(x_pl, DIM, DIM, NUM_CLASSES)\n",
    "\n",
    "# y_ is a placeholder variable taking on the value of the target batch.\n",
    "y_pl = tf.placeholder(tf.float32, shape=[None, NUM_CLASSES], name=\"output\")\n",
    "lr_pl = tf.placeholder(tf.float32, shape=[], name=\"learning-rate\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(y_pl * tf.log(model+1e-8), reduction_indices=[1])\n",
    "\n",
    "    # averaging over samples\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# defining our optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr_pl)\n",
    "\n",
    "# applying the gradients\n",
    "train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "# restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "# initialize the Session\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Launch TensorBoard, and visualize the TF graph\n",
    "tmp_def = utils.rename_nodes(sess.graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "utils.show_graph(tmp_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test the forward pass\n",
    "dummy_size = 45\n",
    "x = np.random.normal(0,1, (dummy_size, 1,60,60)).astype('float32') #dummy data\n",
    "\n",
    "res = sess.run(fetches=model, feed_dict={x_pl: x})\n",
    "\n",
    "assert res.shape == (dummy_size, 10), \"ERROR the output shape is not as expected!\" \\\n",
    "        + \" Output shape should be \" + str(y.shape) + ' but was ' + str(y_pred.shape)\n",
    "\n",
    "print('Forward pass successful!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "Unfortunately NVIDIA has yet to squeeze a TitanX into a labtop and training convnets on CPU is painfully slow. After 10 epochs you should see that model starts to zoom in on the digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_epoch(X, y, learning_rate):\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / float(BATCH_SIZE)))\n",
    "    costs = []\n",
    "    correct = 0\n",
    "    for i in range(num_batches):\n",
    "        if i % 10 == 0:\n",
    "            print(i, end=', ')\n",
    "        idx = range(i*BATCH_SIZE, np.minimum((i+1)*BATCH_SIZE, num_samples))\n",
    "        X_batch_tr = X[idx]\n",
    "        y_batch_tr = y[idx]\n",
    "        fetches_tr = [train_op, cross_entropy, model]\n",
    "        feed_dict_tr = {x_pl: X_batch_tr, y_pl: onehot(y_batch_tr, NUM_CLASSES), lr_pl: learning_rate}\n",
    "        res = sess.run(fetches=fetches_tr, feed_dict=feed_dict_tr)\n",
    "        cost_batch, output_train = tuple(res[1:3])\n",
    "        costs += [cost_batch]\n",
    "        preds = np.argmax(output_train, axis=-1)\n",
    "        correct += np.sum(y_batch_tr == preds)\n",
    "    print(\"\")\n",
    "    return np.mean(costs), correct / float(num_samples)\n",
    "\n",
    "\n",
    "def eval_epoch(X, y):\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = int(np.ceil(num_samples / float(BATCH_SIZE)))\n",
    "    pred_list = []\n",
    "    transform_list = []\n",
    "    for i in range(num_batches):\n",
    "        if i % 10 == 0:\n",
    "            print(i, end=', ')\n",
    "        idx = range(i*BATCH_SIZE, np.minimum((i+1)*BATCH_SIZE, num_samples))\n",
    "        X_batch_val = X[idx]\n",
    "        fetches_val = [model, l_transform]\n",
    "        feed_dict_val = {x_pl: X_batch_val}\n",
    "        res = sess.run(fetches=fetches_val, feed_dict=feed_dict_val)\n",
    "        output_eval, transform_eval = tuple(res)\n",
    "        pred_list.append(output_eval)\n",
    "        transform_list.append(transform_eval)\n",
    "    transform_eval = np.concatenate(transform_list, axis=0)\n",
    "    preds = np.concatenate(pred_list, axis=0)\n",
    "    preds = np.argmax(preds, axis=-1)\n",
    "    acc = np.mean(preds == y)\n",
    "    print('')\n",
    "    return acc, transform_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_accs, train_accs, test_accs = [], [], []\n",
    "learning_rate=0.0001\n",
    "print('Number of epochs: %s' % NUM_EPOCHS)\n",
    "\n",
    "try:\n",
    "    for n in range(NUM_EPOCHS):\n",
    "        print(\"Epoch %d:\" % n, end=', ')\n",
    "        print('train:', end=', ')\n",
    "        train_cost, train_acc = train_epoch(data['X_train'], data['y_train'], learning_rate)\n",
    "        print('valid:', end=', ')\n",
    "        valid_acc, valid_trainsform = eval_epoch(data['X_valid'], data['y_valid'])\n",
    "        print('test:', end=', ')\n",
    "        test_acc, test_transform = eval_epoch(data['X_test'], data['y_test'])\n",
    "        valid_accs += [valid_acc]\n",
    "        test_accs += [test_acc]\n",
    "        train_accs += [train_acc]\n",
    "\n",
    "        # learning rate annealing\n",
    "        if (n+1) % 20 == 0:\n",
    "            learning_rate = learning_rate * 0.7\n",
    "            print(\"New LR:\", learning_rate)\n",
    "\n",
    "        print(\"train cost {0:.2}, train acc {1:.2}, val acc {2:.2}, test acc {3:.2}\".format(\n",
    "                train_cost, train_acc, valid_acc, test_acc))\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot errors and zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.plot(1-np.array(train_accs), label='Training Error')\n",
    "plt.plot(1-np.array(valid_accs), label='Validation Error')\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.ylabel('Error', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,14))\n",
    "for i in range(3):\n",
    "    plt.subplot(321+i*2)\n",
    "    plt.imshow(data['X_test'][i].reshape(DIM, DIM), cmap='gray', interpolation='none')\n",
    "    if i == 0:\n",
    "        plt.title('Original 60x60', fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(322+i*2)\n",
    "    plt.imshow(test_transform[i].reshape(DIM//3, DIM//3).T, cmap='gray', interpolation='none')\n",
    "    if i == 0:\n",
    "        plt.title('Transformed 20x20', fontsize=20)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
