{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import datetime\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from tensorflow.python.framework.ops import reset_default_graph\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import os\n",
    "import subprocess\n",
    "import itertools\n",
    "import data_utils\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join('.', '..')) # Allow us to import shared custom \n",
    "                                         # libraries, like utils.py\n",
    "import utils # contain various helper funcitons that aren't \n",
    "             # important to understand\n",
    "\n",
    "def onehot(t, num_classes):\n",
    "    out = np.zeros((t.shape[0], num_classes))\n",
    "    for row, col in enumerate(t):\n",
    "        out[int(row), int(col)] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tying everything together\n",
    "\n",
    "Now that you have learned about the three most used network architectures: FNNs, CNNs and RNNs. It is time to combine these network types into a more advanced model. \n",
    "\n",
    "It often happens that you have a combination of data that cannot fully be modeled by one of these three types of network. Knowing how to divide the data into the right subsets, and then build a network that handles each subset efficiently can mean the difference between a great model and an unusable one. \n",
    "\n",
    "## Kaggle challenge\n",
    "\n",
    "In this lab we will work on a data science challenge from [`kaggle.com`](kaggle.com).\n",
    "Kaggle is a website to participate in real life challenges. Early 2017 it was bought by Google, who wanted access to the global community of data scientists it has created over the last 7 years. Since then Google have sponsored its expansion and now the prizes of the competitions and the amount of public datasets are bigger than ever. Most competitions on Kaggle have a dataset, an accuracy metric and a leaderboard to compare submissions.\n",
    "You can read more about Kaggle [here](https://www.kaggle.com/about) and access a great amount of public datasets [here](https://www.kaggle.com/datasets).\n",
    "\n",
    "**NB**: You will need a Kaggle account for this exercise!\n",
    "\n",
    "The challenge we will pursue is the [_Leaf Classification_](https://www.kaggle.com/c/leaf-classification) challenge.\n",
    "The dataset consists approximately 1,584 images of leaf specimens (16 samples each of 99 species) which have been converted to binary black leaves against white backgrounds. Three sets of features are also provided per image: a shape contiguous descriptor, an interior texture histogram, and a Ô¨Åne-scale margin histogram. For each feature, a 64-attribute vector is given per leaf sample.\n",
    "\n",
    "We will primarily look into the type of neural network best suited for handling this type of data. \n",
    " * For images, usually the convolutional neural network does a pretty good job, \n",
    " * For timeseries (like the shape) usually the RNN is the network of choice\n",
    " * For the describing features a FFN is often a great option\n",
    "\n",
    "Lastly, we will train the model and put the outputs in a submission file that we can submit to kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "\n",
    "First we start out by looking at the images. We have already downloaded them for you, so all you have to do is to load the files into memory. For this, `glob` is a fantastic tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_paths = glob.glob(\"images/*.jpg\")\n",
    "print(\"Amount of images =\", len(image_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load in the training data, which is in CSV format. For this, we use [pandas](https://pandas.pydata.org/). Pandas is probably the most commonly used python library for Data Analysis, so if you have not worked with it before, you should probably check it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now loading the train.csv to find features for each training point\n",
    "train = pd.read_csv('train.csv')\n",
    "train_images = ['images/{}.jpg'.format(i) for i in train.id.values]\n",
    "# notice how we \"only\" have 990 (989+0 elem) images for training, the rest is for testing\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our training data and images loaded into memory. It is time to take a look at the data. Trying to classify leaves does not sound like a particularly difficult or interesting problem. We have probably all had teachers forcing us to do it on field trips as children.\n",
    "\n",
    "But try to take a look at the 99 different categories and come up with a system that discern all 99 types of leaves from each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First we find an example of each species in order to visualize it\n",
    "species = np.array(sorted(train.species.unique()))\n",
    "species_examples = [np.random.choice(train[train.species == s].id.values) for s in species]\n",
    "\n",
    "# Then we gather its' index in our list of images in order to find the correct image\n",
    "indexes = [image_paths.index('images/{}.jpg'.format(i)) for i in species_examples]\n",
    "\n",
    "# now plot 1 image from each category\n",
    "fig = plt.figure(figsize=(50, 50))\n",
    "for i, idx in enumerate(indexes):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    image = imread(image_paths[idx], as_grey=True)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(\"%s\" % (species[i]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, classifying leaves is actually a very tough problem. What makes it even worse, is that we cannot use all the image data we have available. In order to decrease the amount of computations needed, we need to reduce the size of the images as much as possible. On top of that our neural network only accepts fixed size input tensors. This means we will have to resize the images to ensure they all have the same sizes.\n",
    "\n",
    "This resizing is problematic because it alters the shape of the leaves, and for some of them, this is their most distinctive feature. Take a look at `Salix_Intergra` in the bottom left corner. Describing this leaf without taking its' shape into account seems extremely difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "amount = 5\n",
    "image_sample = np.random.choice(train_images, amount)\n",
    "\n",
    "ax = plt.subplot(2, amount + 1, 1)\n",
    "txt = ax.text(0.4, 0.5, 'Original', fontsize=20)\n",
    "txt.set_clip_on(False)\n",
    "plt.axis('off')\n",
    "    \n",
    "for i, path in enumerate(image_sample):\n",
    "    plt.subplot(2, amount + 1, i + 2)\n",
    "    image = imread(path, as_grey=True)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    _id = int(path.split('/')[-1].split('.')[0])\n",
    "    plt.title(\"{0}\\nshape: {1}\".format(train[train.id == _id].species.values[0], image.shape))\n",
    "    plt.axis('off')\n",
    "\n",
    "ax = plt.subplot(2, amount + 1, len(image_sample) + 2)\n",
    "txt = ax.text(0.4, 0.5, 'Resized', fontsize=20)\n",
    "txt.set_clip_on(False)\n",
    "plt.axis('off')\n",
    "    \n",
    "for i, path in enumerate(image_sample):\n",
    "    i += len(image_sample) + 3\n",
    "    plt.subplot(2, amount + 1, i)\n",
    "    image = imread(path, as_grey=True)\n",
    "    \n",
    "    image = resize(image, output_shape=(300, 300)) # <-- This is the method that resizes the image\n",
    "    \n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now do similar as in train example above for test.csv\n",
    "test = pd.read_csv('test.csv')\n",
    "# notice that we do not have species here, we need to predict that ..!\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and now do similar as in train example above for test.csv\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "# accordingly to these IDs we need to provide the probability of a given plant being present\n",
    "sample_submission.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the other features\n",
    "\n",
    "Now that we have looked at the image data we have available, it is time to take a look at the other available features. Below we choose a random subset of the training data, and visualize the 3 types of available features:\n",
    "* margin\n",
    "* shape\n",
    "* texture\n",
    "\n",
    "Try to run it a few times to try and get an understanding of how the features differ from species to species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try and extract and plot columns\n",
    "X = train.as_matrix()\n",
    "species = X[:, 1:2]\n",
    "margin = X[:, 2:66]\n",
    "shape = X[:, 66:130]\n",
    "texture = X[:, 130:]\n",
    "\n",
    "# let us plot some of the features\n",
    "plt.figure(figsize=(21,7)) # Set the plot size\n",
    "amount = 5 # Choose the amount of images we want to show at a time\n",
    "for i, idx in enumerate(np.random.choice(range(len(train)), amount)):\n",
    "    ax = plt.subplot(amount,4,1+i*4)\n",
    "    txt = ax.text(0.2, 0.2, species[idx][0], fontsize=20)\n",
    "    txt.set_clip_on(False)\n",
    "    plt.axis('off')\n",
    "    if i == 0:\n",
    "        plt.title('Species', fontsize=20)\n",
    "    plt.subplot(amount,4,2+i*4)\n",
    "    plt.plot(margin[idx])\n",
    "    if i == 0:\n",
    "        plt.title('Margin', fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(amount,4,3+i*4)\n",
    "    plt.plot(shape[idx])\n",
    "    if i == 0:\n",
    "        plt.title('Shape', fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(amount,4,4+i*4)\n",
    "    plt.plot(texture[idx])\n",
    "    if i == 0:\n",
    "        plt.title('Texture', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "1. Test various resizings of the image until you have found the smallest resizing of the image where you can still see differentiate between the images. Use IMAGE_SHAPE=(?, ?, 1) to reflect your choices.\n",
    "\n",
    "So far we have learned about the feed forward neural network, the convolutional neural network and the recurrent neural network.\n",
    "Given margin and texture are histograms, shape is a contigious value over a \"time\" dimension \n",
    "\n",
    "* (Optional) How could Margin, Shape and Texture be represented for classification?\n",
    "\n",
    "* (Optional) Describe what network you would build and how you would represent the data points (image, margin, shape and texture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Defining the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading data and setting up constants\n",
    "TRAIN_PATH = \"train.csv\"\n",
    "TEST_PATH = \"test.csv\"\n",
    "IMAGE_PATHS = glob.glob(\"images/*.jpg\")\n",
    "NUM_CLASSES = 99\n",
    "IMAGE_SHAPE = (128, 128, 1)\n",
    "NUM_FEATURES = 64 # for all three features, margin, shape and texture\n",
    "# train holds both X (input) and t (target/truth)\n",
    "data = data_utils.load_data(train_path=TRAIN_PATH, \n",
    "                 test_path=TEST_PATH,\n",
    "                 image_paths=IMAGE_PATHS,\n",
    "                 image_shape=IMAGE_SHAPE[:2])\n",
    "# to visualize the size of the dimensions of the data\n",
    "# print\n",
    "print(\"@@@Shape checking of data sets@@@\")\n",
    "# print\n",
    "print(\"TRAIN\")\n",
    "print(\"\\timages\\t%s%f\" % (data.train['images'].shape, data.train['images'].mean()))\n",
    "print(\"\\tmargins\\t%s\\t%f\" % (data.train['margins'].shape, data.train['margins'].mean()))\n",
    "print(\"\\tshapes\\t%s\\t%f\" % (data.train['shapes'].shape, data.train['shapes'].mean()))\n",
    "print(\"\\ttextures%s\\t%f\" % (data.train['textures'].shape, data.train['textures'].mean()))\n",
    "print(\"\\tts\\t %s\" % (data.train['ts'].shape))\n",
    "print(\"\\twhile training, batch_generator will onehot encode ts to (batch_size, num_classes)\")\n",
    "# print()\n",
    "print(\"TEST\")\n",
    "print(\"\\timages\\t%s\\t%f\" % (data.test['images'].shape, data.test['images'].mean())) \n",
    "print(\"\\tmargins\\t%s\\t%f\" % (data.test['margins'].shape, data.test['margins'].mean()))\n",
    "print(\"\\tshapes\\t%s\\t%f\" % (data.test['shapes'].shape, data.test['shapes'].mean()))\n",
    "print(\"\\ttextures%s\\t%f\" % (data.test['textures'].shape, data.test['textures'].mean()))\n",
    "print(\"\\tids\\t%s\" % (data.test['ids'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Generator\n",
    "\n",
    "While training, we will not directly access the entire dataset, instead we have a `batch_generator` function to give us inputs aligned with their targets/ids in a size that our model can handle in memory (batch\\_size).\n",
    "\n",
    "Furthermore, the `batch_generator` also handles validation splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dummy_batch_gen = data_utils.batch_generator(data, batch_size=64, num_classes=99, num_iterations=5e3, seed=42)\n",
    "train_batch = next(dummy_batch_gen.gen_train())\n",
    "valid_batch, i = next(dummy_batch_gen.gen_valid())\n",
    "test_batch, i = next(dummy_batch_gen.gen_test())\n",
    "\n",
    "print(\"TRAIN\")\n",
    "print(\"\\timages,\", train_batch['images'].shape)\n",
    "print(\"\\tmargins,\", train_batch['margins'].shape)\n",
    "print(\"\\tshapes,\", train_batch['shapes'].shape)\n",
    "print(\"\\ttextures,\", train_batch['textures'].shape)\n",
    "print(\"\\tts,\", train_batch['ts'].shape)\n",
    "print()\n",
    "print(\"VALID\")\n",
    "print(\"\\timages,\", valid_batch['images'].shape)\n",
    "print(\"\\tmargins,\", valid_batch['margins'].shape)\n",
    "print(\"\\tshapes,\", valid_batch['shapes'].shape)\n",
    "print(\"\\ttextures,\", valid_batch['textures'].shape)\n",
    "print(\"\\tts,\", valid_batch['ts'].shape)\n",
    "print()\n",
    "print(\"TEST\")\n",
    "print(\"\\timages,\", test_batch['images'].shape)\n",
    "print(\"\\tmargins,\", test_batch['margins'].shape)\n",
    "print(\"\\tshapes,\", test_batch['shapes'].shape)\n",
    "print(\"\\ttextures,\", test_batch['textures'].shape)\n",
    "print(\"\\tids,\", len(test_batch['ids']))\n",
    "# notice that mean is very different, which is why we use batch_norm in all input data in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation on contrib layers\n",
    "Check out the [documentation page](https://www.tensorflow.org/api_docs/python/tf/contrib/layers) for information on contrib layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, convolution2d, flatten, batch_norm, max_pool2d, dropout\n",
    "from tensorflow.python.ops.nn import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from tensorflow.python.ops.nn import dynamic_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wrapping conv with batch_norm\n",
    "def conv(l_in, num_outputs, kernel_size, scope, stride=1):\n",
    "    return convolution2d(l_in, num_outputs=num_outputs, kernel_size=kernel_size,\n",
    "                         stride=stride, normalizer_fn=batch_norm, scope=scope)\n",
    "\n",
    "# pre-activation: http://arxiv.org/abs/1603.05027\n",
    "# wrapping convolutions and batch_norm\n",
    "def conv_pre(l_in, num_outputs, kernel_size, scope, stride=1):\n",
    "    l_norm = batch_norm(l_in)\n",
    "    l_relu = relu(l_norm)\n",
    "    return convolution2d(l_relu, num_outputs=num_outputs, kernel_size=kernel_size,\n",
    "                         stride=stride, activation_fn=None, scope=scope)\n",
    "\n",
    "# easy to use pool function\n",
    "def pool(l_in, scope, kernel_size=(3, 3)):\n",
    "    return max_pool2d(l_in, kernel_size=kernel_size, scope=scope) # (3, 3) has shown to work better than (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hyperameters of the model\n",
    "height, width, channels = IMAGE_SHAPE\n",
    "# resetting the graph ...\n",
    "reset_default_graph()\n",
    "\n",
    "# Setting up placeholder, this is where your data enters the graph!\n",
    "x_image_pl = tf.placeholder(tf.float32, [None, height, width, channels], name=\"x-image_pl\")\n",
    "x_margin_pl = tf.placeholder(tf.float32, [None, NUM_FEATURES], name=\"x-margin_pl\")\n",
    "x_shape_pl = tf.placeholder(tf.float32, [None, NUM_FEATURES], name=\"x-shape_pl\")\n",
    "x_texture_pl = tf.placeholder(tf.float32, [None, NUM_FEATURES], name=\"x-texture_pl\")\n",
    "is_training_pl = tf.placeholder(tf.bool, name=\"is-training_pl\")\n",
    "\n",
    "# Building the layers of the neural network\n",
    "# we define the variable scope, so we more easily can recognise our variables later\n",
    "\n",
    "## IMAGE\n",
    "#with tf.name_scope('image-features'):\n",
    "#    l_conv1_a = conv(x_image_pl, 16, (5, 5), scope=\"l-conv1_a\")\n",
    "#    l_pool1 = pool(l_conv1_a, scope=\"l-pool1\")\n",
    "#    l_conv2_a = conv(l_pool1, 16, (5, 5), scope=\"l-conv2_a\")\n",
    "#    l_pool2 = pool(l_conv2_a, scope=\"l-pool2\")\n",
    "#    l_conv3_a = conv(l_pool2, 16, (5, 5), scope=\"l-conv3_a\")\n",
    "#    l_pool3 = pool(l_conv3_a, scope=\"l-pool3\")\n",
    "#    l_conv4_a = conv(l_pool3, 16, (5, 5), scope=\"l-conv4_a\")\n",
    "#    l_pool4 = pool(l_conv3_a, scope=\"l-pool4\")\n",
    "#    l_flatten = flatten(l_pool4, scope=\"flatten\")\n",
    "\n",
    "## RNN\n",
    "# define the cell of your RNN\n",
    "#shape_cell = tf.nn.rnn_cell.GRUCell(100)\n",
    "# run the RNN as outputs, state = tf.nn.dynamic_rnn(cell, ...)\n",
    "# given we run many-to-one we only care about the last state, so only\n",
    "# shape_state is defined\n",
    "#_, shape_state = tf.nn.dynamic_rnn(cell=shape_cell,\n",
    "#    inputs=tf.expand_dims(batch_norm(x_shape_pl), 2), dtype=tf.float32, scope=\"shape_rnn\")\n",
    "\n",
    "## COMBINE\n",
    "# use margin, shape and texture only\n",
    "features = tf.concat(values=[x_margin_pl, x_shape_pl, x_texture_pl], axis=1, name=\"features\")\n",
    "# uncomment to use image only\n",
    "#features = l_flatten\n",
    "# uncomment to use margin, rnn_state on shape and texture only\n",
    "#features = tf.concat(concat_dim=1, values=[x_margin_pl, shape_state, x_texture_pl], name=\"features\")\n",
    "features = batch_norm(features, scope='features_bn')\n",
    "#l2 = fully_connected(features, num_outputs=256, activation_fn=relu,\n",
    "#                     normalizer_fn=batch_norm, scope=\"l2\")\n",
    "#l2 = dropout(l2, is_training=is_training_pl, scope=\"l2_dropout\")\n",
    "y = fully_connected(features, NUM_CLASSES, activation_fn=softmax, scope=\"y\")\n",
    "\n",
    "# add TensorBoard summaries for all variables\n",
    "tf.summary.merge_all()\n",
    "\n",
    "# restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "# initialize the Session\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Launch TensorBoard, and visualize the TF graph\n",
    "tmp_def = utils.rename_nodes(sess.graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "utils.show_graph(tmp_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PRINT NETWORK (good practice to also include outcommented code when using it)\n",
    "\n",
    "print(\"x_image_pl,\", x_image_pl.get_shape())\n",
    "print(\"x_margin_pl,\", x_margin_pl.get_shape())\n",
    "print(\"x_shape_pl,\", x_shape_pl.get_shape())\n",
    "print(\"x_texture_pl,\", x_texture_pl.get_shape())\n",
    "print(\"features,\", features.get_shape())\n",
    "print(\"y,\", y.get_shape())\n",
    "\n",
    "# for the MLP\n",
    "#print(\"l2,\", l2.get_shape())\n",
    "# for the RNN\n",
    "#print(\"shape_state,\", shape_state.get_shape())\n",
    "# for the CNN\n",
    "#print(\"l_conv1_a,\", l_conv1_a.get_shape())\n",
    "#...\n",
    "#print(\"l_pool4,\", l_pool4.get_shape())\n",
    "#print(\"l_flatten,\", l_flatten.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clip_norm = 1\n",
    "# y_ is a placeholder variable taking on the value of the target batch.\n",
    "ts_pl = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"targets_pl\")\n",
    "lr_pl = tf.placeholder(tf.float32, [], name=\"learning_rate_pl\")\n",
    "\n",
    "def loss_and_acc(preds):\n",
    "    # computing cross entropy per sample\n",
    "    cross_entropy = -tf.reduce_sum(ts_pl * tf.log(preds+1e-10), reduction_indices=[1])\n",
    "    # averaging over samples\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "    # if you want regularization\n",
    "    #reg_scale = 0.0001\n",
    "    #regularize = tf.contrib.layers.l2_regularizer(reg_scale)\n",
    "    #params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    #reg_term = sum([regularize(param) for param in params])\n",
    "    #loss += reg_term\n",
    "    # calculate accuracy\n",
    "    argmax_y = tf.to_int32(tf.argmax(preds, axis=1))\n",
    "    argmax_t = tf.to_int32(tf.argmax(ts_pl, axis=1))\n",
    "    correct = tf.to_float(tf.equal(argmax_y, argmax_t))\n",
    "    accuracy = tf.reduce_mean(correct)\n",
    "    return loss, accuracy, argmax_y\n",
    "\n",
    "### loss, accuracy and prediction\n",
    "loss, accuracy, prediction = loss_and_acc(y) \n",
    "\n",
    "# defining our optimizer\n",
    "LEARNING_RATE = 0.0005\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "\n",
    "# applying the gradients\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "gradients, variables = zip(*grads_and_vars)  # unzip list of tuples\n",
    "clipped_gradients, global_norm = (\n",
    "    tf.clip_by_global_norm(gradients, clip_norm) )\n",
    "clipped_grads_and_vars = zip(clipped_gradients, variables)\n",
    "\n",
    "# make training op for applying the gradients\n",
    "train_op = optimizer.apply_gradients(clipped_grads_and_vars)\n",
    "\n",
    "# make tensorboard summeries\n",
    "tf.summary.scalar('global_gradient_norm', global_norm)\n",
    "tf.summary.scalar('Evaluation/loss', loss)\n",
    "tf.summary.scalar('Evaluation/accuracy', accuracy)\n",
    "\n",
    "# initialize the Session again to add the new operations\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test the forward pass\n",
    "_img_shape = tuple([45]+list(IMAGE_SHAPE))\n",
    "_feature_shape = (45, NUM_FEATURES)\n",
    "_x_image = np.random.normal(0, 1, _img_shape).astype('float32') #dummy data\n",
    "_x_margin = np.random.normal(0, 1, _feature_shape).astype('float32')\n",
    "_x_shape = np.random.normal(0, 1, _feature_shape).astype('float32')\n",
    "_x_texture = np.random.normal(0, 1, _feature_shape).astype('float32')\n",
    "\n",
    "# test the forward pass\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {x_image_pl: _x_image,\n",
    "             x_margin_pl: _x_margin,\n",
    "             x_shape_pl: _x_shape,\n",
    "             x_texture_pl: _x_texture,\n",
    "             is_training_pl: False}\n",
    "res_forward_pass = sess.run(fetches=[y], feed_dict=feed_dict)\n",
    "print(\"y\", res_forward_pass[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "\n",
    "The code above has TensorBoard tracking histograms of all layers, train gradient norm, accuracy, loss, validation accuracy and loss.\n",
    "\n",
    "The TensorBoard summaries are written to the tensorboard folder. To start TensorBoard run the following command: \n",
    "\n",
    "    tensorboard --logdir=tensorboard\n",
    "\n",
    "in a shell. For ease of use we have included a cell which launches tensorboard in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell runs tensorboard in the background which means it can be watched live while training\n",
    "# Go to http://your.ip.address:6006 in order to see the tensorboard\n",
    "import subprocess\n",
    "subprocess.Popen([\"tensorboard\",\"--logdir=tensorboard\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also launc tensorboard manually in Jupyter.\n",
    "\n",
    "In the Jupyter homescreen (where you choose exercises) in the top right click '`New >> Terminal`'. Then open a browser window and connect to `localhost:6006`, here you should find the TensorBoard of your current run.\n",
    "\n",
    "**DEBUG**: If TensorBoard is empty it is most likely because you aren't pointing the the correct folder.\n",
    "\n",
    "You can read more about [Tensorboard here](https://www.tensorflow.org/how_tos/summaries_and_tensorboard/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "BATCH_SIZE = 64\n",
    "ITERATIONS = 1e4\n",
    "LOG_FREQ = 10\n",
    "VALIDATION_SIZE = 0.1 # 0.1 is ~ 100 samples for valition\n",
    "SEED = 42\n",
    "DROPOUT = False\n",
    "VALID_EVERY = 100\n",
    "\n",
    "batch_gen = data_utils.batch_generator(data, batch_size=BATCH_SIZE, num_classes=NUM_CLASSES,\n",
    "                            num_iterations=ITERATIONS, seed=SEED, val_size=VALIDATION_SIZE)\n",
    "\n",
    "# setup and write summaries\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "summaries_path = \"tensorboard/%s\" % (timestamp)\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "summarywriter_train = tf.summary.FileWriter(summaries_path + '/train', sess.graph)\n",
    "summarywriter_valid = tf.summary.FileWriter(summaries_path + '/valid', sess.graph)\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "print(\"\\ttrain_loss \\ttrain_acc \\tvalid_loss \\tvalid_acc\")\n",
    "try:\n",
    "    for i, batch_train in enumerate(batch_gen.gen_train()):\n",
    "        if i>=ITERATIONS:\n",
    "            break\n",
    "        fetches_train = [train_op, loss, accuracy, summaries]\n",
    "        feed_dict_train = {\n",
    "            x_image_pl: batch_train['images'],\n",
    "            x_margin_pl: batch_train['margins'],\n",
    "            x_shape_pl: batch_train['shapes'],\n",
    "            x_texture_pl: batch_train['textures'],\n",
    "            ts_pl: batch_train['ts'],\n",
    "            is_training_pl: DROPOUT,\n",
    "            lr_pl: LEARNING_RATE,\n",
    "\n",
    "        }\n",
    "        res_train = sess.run(fetches=fetches_train, feed_dict=feed_dict_train)\n",
    "        if i % LOG_FREQ == 0:\n",
    "            summarywriter_train.add_summary(res_train[3], i)\n",
    "        train_loss.append(res_train[1])\n",
    "        train_acc.append(res_train[2])\n",
    "\n",
    "        # validate\n",
    "        if i % VALID_EVERY == 0:\n",
    "            cur_acc = 0\n",
    "            cur_loss = 0\n",
    "            tot_num = 0\n",
    "            # batch validation\n",
    "            for batch_valid, num in batch_gen.gen_valid():\n",
    "                # fetches and feed_dict for validation\n",
    "                fetches_valid = [loss, accuracy, summaries]\n",
    "                feed_dict_valid = {\n",
    "                    x_image_pl: batch_valid['images'],\n",
    "                    x_margin_pl: batch_valid['margins'],\n",
    "                    x_shape_pl: batch_valid['shapes'],\n",
    "                    x_texture_pl: batch_valid['textures'],\n",
    "                    ts_pl: batch_valid['ts'],\n",
    "                    is_training_pl: False,\n",
    "                }\n",
    "                # run validation\n",
    "                res_valid = sess.run(fetches=fetches_valid, feed_dict=feed_dict_valid)\n",
    "                # tensorboard and costs\n",
    "                cur_loss += res_valid[0]*num   # Validation loss\n",
    "                cur_acc  += res_valid[1]*num   # Validation accuracy \n",
    "                summarywriter_valid.add_summary(res_valid[2], i) # save the vali summary\n",
    "                tot_num += num\n",
    "\n",
    "            valid_loss = cur_loss / float(tot_num)\n",
    "            valid_acc = (cur_acc / float(tot_num)) * 100\n",
    "            train_loss = sum(train_loss) / float(len(train_loss))\n",
    "            train_acc = sum(train_acc) / float(len(train_acc)) * 100\n",
    "            print(\"%d:\\t  %.2f\\t\\t  %.1f\\t\\t  %.2f\\t\\t  %.1f\" % (i, train_loss, train_acc, valid_loss, valid_acc))\n",
    "            train_loss = []\n",
    "            train_acc = []\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission to Kaggle\n",
    "\n",
    "First we have to make testset predictions, then we have to place it in the submission file and the upload to kaggle for our score! You can upload at max 5 submissions a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET PREDICTIONS\n",
    "# containers to collect ids and predictions\n",
    "ids_test = []\n",
    "preds_test = []\n",
    "# run like with validation\n",
    "for batch_test, num in batch_gen.gen_test():\n",
    "    # fetching for test we only need y\n",
    "    fetches_test = [y]\n",
    "    # same as validation, but no batch['ts']\n",
    "    feed_dict_test = {\n",
    "        x_image_pl: batch_test['images'],\n",
    "        x_margin_pl: batch_test['margins'],\n",
    "        x_shape_pl: batch_test['shapes'],\n",
    "        x_texture_pl: batch_test['textures'],\n",
    "        is_training_pl: False\n",
    "    }\n",
    "    # get the result\n",
    "    res_test = sess.run(fetches=fetches_test, feed_dict=feed_dict_test)\n",
    "    y_out = res_test[0]\n",
    "    ids_test.append(batch_test['ids'])\n",
    "    if num!=len(y_out):\n",
    "        # in case of the last batch, num will be less than batch_size\n",
    "        y_out = y_out[:num]\n",
    "    preds_test.append(y_out)\n",
    "# concatenate it all, to form one list/array\n",
    "ids_test = list(itertools.chain.from_iterable(ids_test))\n",
    "preds_test = np.concatenate(preds_test, axis=0)\n",
    "assert len(ids_test) == len(preds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(preds_test, columns=data.le.classes_)\n",
    "ids_test_df = pd.DataFrame(ids_test, columns=[\"id\"])\n",
    "submission = pd.concat([ids_test_df, preds_df], axis=1)\n",
    "submission.to_csv('submission_mlp.csv', index=False)\n",
    "# below prints the submission, can be removed and replaced with code block below\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload submission\n",
    "\n",
    "1. Go to [`https://www.kaggle.com/c/leaf-classification/`](https://www.kaggle.com/c/leaf-classification/)\n",
    "2. Make a submission\n",
    "3. Click or drop your submission here (writing a description is good practice)\n",
    "4. Submit\n",
    "\n",
    "Success! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "1. Try to get the best score on Kaggle for this dataset as you can. (You can upload your solution multiple times as you progress)\n",
    "\n",
    "A good implementation would get a score around 0.06399, try and see if you can get there, and explain what might have gone wrong if you cant. \n",
    "\n",
    "When doing trying to improve the network nothing is sacred, you can change learning rate, try testing various learning rates, batch sizes, validation sizes, etc. And most importantly, the validation set is very small (only 1 sample per class), etc.\n",
    "\n",
    "To get you of to a good start we have created a list of thing you might want to try:\n",
    "* Include l2 (fully connected and dropout layer)\n",
    "* Try with L1 regularization (look at [tensorflow API](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/l1_regularizer) for instructions)\n",
    "* Include Dropout (Set DROPOUT to TRUE)\n",
    "* Include L2 regularization\n",
    "* Use only the image for training (with CNN) - comment on the increased time between iterations.\n",
    "* Use dropout between the convolutional layers\n",
    "* Include the RNN part\n",
    "* Increase or decrease the batch size \n",
    "* Change the image size to be rectangular, bigger or smaller\n",
    "* Try to combine the FFN, CNN, RNN parts in various ways\n",
    "\n",
    "If your network is not performing as well as you would like it to, [here](http://theorangeduck.com/page/neural-network-not-working) is a great explanation of what might have gone wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py3]",
   "language": "python",
   "name": "Python [py3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
