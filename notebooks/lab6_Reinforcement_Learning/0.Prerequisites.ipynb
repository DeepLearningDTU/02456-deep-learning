{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "In this lab we will train a neural network reinforcement learning agent with [TensorFlow](https://www.tensorflow.org/) to navigate various environments from [OpenAI Gym](https://gym.openai.com/) provided by [OpenAI](https://openai.com/).\n",
    "\n",
    "Please refer to the [docs](https://gym.openai.com/docs/) on how to get started with Gym. You are also encouraged to reed this short [blog post](https://blog.openai.com/openai-gym-beta/) to learn about OpenAI Gym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "**Note: If you are running this lab on a server, everythong you need is already installed and you can skip this step.**\n",
    "\n",
    "Below is a brief guide on how to install OpenAI Gym. For more details, please refer to the repository on [GitHub](https://github.com/openai/gym) and the [docs](https://gym.openai.com/docs).\n",
    "\n",
    "You can perform a minimal install of `gym` with:\n",
    "\n",
    "```\n",
    "git clone https://github.com/openai/gym.git\n",
    "cd gym\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "If you prefer, you can do a minimal install of the packaged version directly from PyPI:\n",
    "\n",
    "```\n",
    "pip install gym\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an environment\n",
    "\n",
    "Here's a bare minimum example of getting something running. This will run an instance of the [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) environment for 200 timesteps, taking random actions rendering the environment at each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-27 18:39:37,812] Making new env: CartPole-v0\n",
      "[2017-09-27 18:39:38,179] You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(200):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classic cart-pole problem, the task is to balance a pole attached to a cart by moving the cart left and right. Taking random action, as shown in the code above, does not cut it. We have to do something smarter. Later we will learn to solve the task by applying reinforcement learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
