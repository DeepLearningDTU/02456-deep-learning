{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "In this lab we will train a neural network reinforcement learning agent with [TensorFlow](https://www.tensorflow.org/) to navigate various environments from [OpenAI Gym](https://gym.openai.com/) provided by [OpenAI](https://openai.com/).\n",
    "\n",
    "Please refer to the [docs](https://gym.openai.com/docs/) on how to get started with Gym. You are also encouraged to reed this short [blog post](https://blog.openai.com/openai-gym-beta/) to learn about OpenAI Gym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "**Note: If you are running this lab on a server, everything you need is already installed and you can skip this step.**\n",
    "\n",
    "Below is a brief guide on how to install OpenAI Gym. For more details, please refer to the Gym repository on [GitHub](https://github.com/openai/gym) and the [docs](https://gym.openai.com/docs).\n",
    "\n",
    "You can perform a minimal install of `gym` with:\n",
    "\n",
    "```\n",
    "git clone https://github.com/openai/gym.git\n",
    "cd gym\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "If you prefer, you can do a minimal install of the packaged version directly from PyPI:\n",
    "\n",
    "```\n",
    "pip install gym\n",
    "```\n",
    "\n",
    "You will also need `JSAnimation` to render the Gym environments in the notebooks.\n",
    "\n",
    "```\n",
    "pip install git+https://github.com/jakevdp/JSAnimation.git\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an environment\n",
    "\n",
    "Here's a bare minimum example of getting something running. This will run an instance of the [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) environment for 200 timesteps, taking random actions and rendering the environment at each step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from utils import Viewer\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "view = Viewer(env, custom_render=True) # we use this custom viewer to render the environment in docker and on a server\n",
    "for _ in range(200):\n",
    "    view.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "view.render(close=True, display_gif=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classic cart-pole problem, the task is to balance a pole attached to a cart by moving the cart left and right. Taking random action, as shown in the code above, does not cut it. We have to do something smarter. Later we will learn to solve the task by applying reinforcement learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
