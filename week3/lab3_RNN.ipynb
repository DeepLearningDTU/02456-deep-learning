{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%matplotlib nbagg\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from data_generator import get_batch, print_valid_characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Recurrent neural networks are the natural choice for sequential data i.e. time series analysis, translation, speech recognition, biological sequence analysis etc. Recurrent neural networks works by recursively applying the same operation at each time step of the data sequence and having layers that pass information from previous time steps to the current. It can therefore naturally handle input of varying length. Recurrent networks are used for several prediction tasks including: sequence-to-class, sequence tagging, and sequence-to-sequence predictions.\n",
    "\n",
    "In this exercise we'll implement an Encoder-Decoder RNN build with the GRU unit. This type of models have shown impressive performance in Neural Machine Translation and Image Caption generation. \n",
    "\n",
    "For more in depth background material on RNNs please cf. [Supervised Sequence Labelling with Recurrent\n",
    "Neural Networks](https://www.cs.toronto.edu/~graves/preprint.pdf) by Alex Graves.\n",
    "\n",
    "We know that LSTMs and GRUs are difficult to understand. A very good non-mathematical introduction is [Chris Olahs blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) (All the posts are nice and cover various topics within machine-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder\n",
    "In the encoder-decoder architecture, one RNN (blue) encodes the input and a second RNN (red) calculates the target values. One essential step is to let the encoder and decoder communicate. In the simplest approach you use the last hidden state of the encoder to initialize the decoder. Other approaches lets the decoder attend to different parts of the encoded input at different timesteps in the decoding process. \n",
    "\n",
    "<img src=\"files/enc-dec.png\", width=400>\n",
    "\n",
    "In our implementation we use a RNN with gated recurrent units (GRU) as encoder. We then use the last hidden state of the encoder ($h^{enc}_T$) as input to the decoder which is also a RNN with GRU units. \n",
    "\n",
    "### RNNs in Lasagne\n",
    "Lasagne has implementations of LSTM and GRU units. Both layers assume that the input from the layer below have the shape **(Batch_size, seq_len, num_features)**. In this excercise we will use the GRU unit since it only stores a single hidden value per neuron (LSTMs stores two) and is approximately twice as fast.\n",
    "\n",
    "As stated above we will implement an Encoder-Decoder model. The simplest way to do this is to encode the input sequence using the Encoder model. We will then use the last hidden state of the Encoder $h^{enc}_T$ as input to the decoder model, which then uses this information (simply a fixed length vector of numbers) to produce the targets. There is (at least) two ways to input $h^{enc}_T$ into the decoder\n",
    "\n",
    "1. Repeatly use $h^{enc}_T$ as input to the Decoder at each decode time step\n",
    "2. Intialize the decoder using $h^{enc}_T$ and run the decoder without any inputs\n",
    "\n",
    "In this exercise we follow the first approach because it's easier to implement. To do this need to create a lasagne layer that takes $h^{enc}_T$ and repeat it *N_decode_step* times. Below is an implementation of the RepeatLayer. You don't need to know the exact way it works, however make sure that you understand that it takes an input of size *(Batch_size x num_units)* and produces an output of size *(Batch_size x n_decode_steps x num_units)*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RepeatLayer(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, n, **kwargs):\n",
    "        '''\n",
    "        The input is expected to be a 2D tensor of shape \n",
    "        (num_batch, num_features). The input is repeated\n",
    "        n times such that the output will be \n",
    "        (num_batch, n, num_features)\n",
    "        '''\n",
    "        super(RepeatLayer, self).__init__(incoming, **kwargs)\n",
    "        self.n = n\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return tuple([input_shape[0], self.n] + list(input_shape[1:]))\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        #repeat the input n times\n",
    "        tensors = [input]*self.n\n",
    "        stacked = theano.tensor.stack(*tensors)\n",
    "        dim = [1, 0] + range(2, input.ndim + 1)\n",
    "        return stacked.dimshuffle(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "Since RNN models can be very slow to train on large datasets we will generate simpler training data for this exercise. The task for the RNN is simply to translate a string of letters spelling the numbers between 0-9 into the corresponding numbers i.e\n",
    "\n",
    "\"one two five\" --> \"125#\" (we use # as a special end-of-sequence character)\n",
    "\n",
    "To input the strings into the RNN model we translate the characters into a vector of integers using a simple translation table (i.e. 'h'->16, 'o'-> 17 etc). The code below prints a few input/output pairs using the *get_batch* function which randomly produces the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "inputs, input_masks, targets, target_masks, text_inputs, text_targets = \\\n",
    "    get_batch(batch_size=batch_size,max_digits=2,min_digits=1)\n",
    "\n",
    "print \"input types:\", inputs.dtype,  input_masks.dtype, targets.dtype, target_masks.dtype\n",
    "print print_valid_characters()\n",
    "print \"Stop character = #\"\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print \"\\nSAMPLE\",i\n",
    "    print \"TEXT INPUTS:\\t\\t\", text_inputs[i]\n",
    "    print \"TEXT TARGETS:\\t\\t\", text_targets[i]\n",
    "    print \"ENCODED INPUTS:\\t\\t\", inputs[i]\n",
    "    print \"MASK INPUTS:\\t\\t\", input_masks[i]\n",
    "    print \"ENCODED TARGETS:\\t\", targets[i]\n",
    "    print \"MASK TARGETS:\\t\\t\", target_masks[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder model setup\n",
    "Below is the Lasagne model implementation. We use an embedding layer to map from integer to multinomial vector representation.\n",
    "\n",
    "Note that the layer has a lot of print statements which we used for debugging during setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_UNITS_ENC = 10\n",
    "NUM_UNITS_DEC = 10\n",
    "MAX_DIGITS = 20 \n",
    "MIN_DIGITS = MAX_DIGITS #currently only support for same length outputs - we'll leave it for an exercise to add support for varying length targets\n",
    "NUM_INPUTS = 27\n",
    "NUM_OUTPUTS = 11 #(0-9 + '#')\n",
    "\n",
    "\n",
    "#symbolic theano variables. Note that we are using imatrix for X since it goes into the embedding layer\n",
    "x_sym = T.imatrix()\n",
    "y_sym = T.imatrix()\n",
    "xmask_sym = T.matrix()\n",
    "\n",
    "#dummy data to test implementation - We advise to check the output-dimensions of all layers.\n",
    "#One way to do this in lasagne/theano is to forward pass some data through the model and \n",
    "#check the output dimensions of these.\n",
    "#Create some random testdata\n",
    "X = np.random.randint(0,10,size=(BATCH_SIZE,MIN_DIGITS)).astype('int32')\n",
    "Xmask = np.ones((BATCH_SIZE,MIN_DIGITS)).astype('float32')\n",
    "\n",
    "##### ENCODER START #####\n",
    "l_in = lasagne.layers.InputLayer((None, None))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, NUM_INPUTS, NUM_INPUTS, \n",
    "                                      W=np.eye(NUM_INPUTS,dtype='float32'),\n",
    "                                      name='Embedding')\n",
    "#Here we'll remove the trainable parameters from the embeding layer to constrain \n",
    "#it to a simple \"one-hot-encoding\". You can experiment with removing this line\n",
    "l_emb.params[l_emb.W].remove('trainable') \n",
    "#forward pass some data throug the inputlayer-embedding layer and print the output shape\n",
    "print lasagne.layers.get_output(l_emb, inputs={l_in: x_sym}).eval({x_sym: X}).shape\n",
    "\n",
    "l_mask_enc = lasagne.layers.InputLayer((None, None))\n",
    "l_enc = lasagne.layers.GRULayer(l_emb, num_units=NUM_UNITS_ENC, name='GRUEncoder', mask_input=l_mask_enc)\n",
    "print lasagne.layers.get_output(l_enc, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "# slice last index of dimension 1\n",
    "l_last_hid = lasagne.layers.SliceLayer(l_enc, indices=-1, axis=1)\n",
    "print lasagne.layers.get_output(l_last_hid, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "##### END OF ENCODER######\n",
    "\n",
    "\n",
    "##### START OF DECODER######\n",
    "l_in_rep = RepeatLayer(l_last_hid, n=MAX_DIGITS+1) #we add one to allow space for the end of sequence character\n",
    "print lasagne.layers.get_output(l_in_rep, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "l_dec = lasagne.layers.GRULayer(l_in_rep, num_units=NUM_UNITS_DEC, name='GRUDecoder')\n",
    "print lasagne.layers.get_output(l_dec, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "\n",
    "# We need to do some reshape voodo to connect a softmax layer to the decoder.\n",
    "# See http://lasagne.readthedocs.org/en/latest/modules/layers/recurrent.html#examples \n",
    "# In short this line changes the shape from \n",
    "# (batch_size, decode_len, num_dec_units) -> (batch_size*decodelen,num_dec_units). \n",
    "# We need to do this since the softmax is applied to the last dimension and we want to \n",
    "# softmax the output at each position individually\n",
    "l_reshape = lasagne.layers.ReshapeLayer(l_dec, (-1, [2]))\n",
    "print lasagne.layers.get_output(l_reshape, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "l_softmax = lasagne.layers.DenseLayer(l_reshape, num_units=NUM_OUTPUTS, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                                      name='SoftmaxOutput')\n",
    "print lasagne.layers.get_output(l_softmax, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "# reshape back to 3d format (batch_size, decode_len, num_dec_units). Here we tied the batch size to the shape of the symbolic variable for X allowing \n",
    "#us to use different batch sizes in the model.\n",
    "l_out = lasagne.layers.ReshapeLayer(l_softmax, (x_sym.shape[0], -1, NUM_OUTPUTS))\n",
    "print lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "###END OF DECODER######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the cost function and theano functions\n",
    "The targets are categorical, hence we use cross entropy error. We use the Adam optimizer but you\n",
    "can experiment with the different optimizers implemented in [Lasagne](http://lasagne.readthedocs.org/en/latest/modules/updates.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_decoder_train = lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}, \n",
    "                                                deterministic=False)\n",
    "\n",
    "#cost function\n",
    "total_cost = T.nnet.categorical_crossentropy(\n",
    "    T.reshape(output_decoder_train, (-1, NUM_OUTPUTS)), y_sym.flatten())\n",
    "mean_cost = T.mean(total_cost)\n",
    "#accuracy function\n",
    "argmax = T.argmax(output_decoder_train,axis=-1)\n",
    "eq = T.eq(argmax,y_sym)\n",
    "acc = T.mean(eq)  # gives float64 because eq is uint8, T.cast(eq, 'float32') will fix that...\n",
    "\n",
    "#Get parameters of both encoder and decoder\n",
    "all_parameters = lasagne.layers.get_all_params([l_out], trainable=True)\n",
    "\n",
    "print \"Trainable Model Parameters\"\n",
    "print \"-\"*40\n",
    "for param in all_parameters:\n",
    "    print param, param.get_value().shape\n",
    "print \"-\"*40\n",
    "\n",
    "#add grad clipping to avoid exploding gradients\n",
    "all_grads = [T.clip(g,-3,3) for g in T.grad(mean_cost, all_parameters)]\n",
    "all_grads = lasagne.updates.total_norm_constraint(all_grads,3)\n",
    "\n",
    "#Compile Theano functions.\n",
    "updates = lasagne.updates.adam(all_grads, all_parameters, learning_rate=0.005)\n",
    "train_func = theano.function([x_sym, y_sym, xmask_sym], [mean_cost, acc, output_decoder_train], updates=updates)\n",
    "#since we don't have any stochasticity in the network we will just use the training graph without any updates given\n",
    "test_func = theano.function([x_sym, y_sym, xmask_sym], [acc, output_decoder_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate validation data\n",
    "Xval, Xmask_val, Yval, Ymask_val, text_inputs_val, text_targets_val = \\\n",
    "    get_batch(batch_size=5000, max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "print \"Xval\", Xval.shape\n",
    "print \"Yval\", Yval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_interval = 5000\n",
    "samples_to_process = 3e5\n",
    "samples_processed = 0\n",
    "\n",
    "val_samples = []\n",
    "costs, accs = [], []\n",
    "plt.figure()\n",
    "try:\n",
    "    while samples_processed < samples_to_process:\n",
    "        x_, x_masks_, ys_, y_masks_, _, _ = \\\n",
    "            get_batch(batch_size=BATCH_SIZE,max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "        batch_cost, batch_acc, batch_output = train_func(x_, ys_, x_masks_)\n",
    "        costs += [batch_cost]\n",
    "        samples_processed += BATCH_SIZE\n",
    "        #validation data\n",
    "        if samples_processed % val_interval == 0:\n",
    "            #print \"validating\"\n",
    "            val_acc, val_output = test_func(Xval, Yval, Xmask_val)\n",
    "            val_samples += [samples_processed]\n",
    "            accs += [val_acc]\n",
    "            plt.plot(val_samples,accs)\n",
    "            plt.ylabel('Validation Accuracy', fontsize=15)\n",
    "            plt.xlabel('Processed samples', fontsize=15)\n",
    "            plt.title('', fontsize=20)\n",
    "            plt.grid('on')\n",
    "            plt.savefig(\"out.png\")\n",
    "            display.display(display.Image(filename=\"out.png\"))\n",
    "            display.clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot of validation accuracy for each target position\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(np.mean(np.argmax(val_output,axis=2)==Yval,axis=0))\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.xlabel('Target position', fontsize=15)\n",
    "#plt.title('', fontsize=20)\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "#why do the plots look like this? See exercise 4 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot training cost\n",
    "#plt.figure(figsize=(7,7))\n",
    "#plt.plot(costs)\n",
    "#plt.ylabel('Cost', fontsize=15)\n",
    "#plt.xlabel('Number of updates', fontsize=15)\n",
    "#plt.title('Training', fontsize=20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:\n",
    "1. Perform an explorative test of the network by inputting a defined input and evaulate the outputs.\n",
    "2. The model has two GRU networks. The ```GRUEncoder``` and the ```GRUDecoder```. A GRU is parameterized by the  ```{W_in_to_updategate, W_hid_to_updategate, b_updategate, W_in_to_resetgate, W_hid_to_resetgate, b_resetgate,\n",
    "W_in_to_hidden_update, W_hid_to_hidden_update,b_hidden_update}```. Try to explain the shape of ```W_in_to_updategate``` and ```hid_to_updategate```. Why are they different? You can find the equations for the gru at: [GRU](http://lasagne.readthedocs.io/en/latest/modules/layers/recurrent.html#lasagne.layers.GRULayer). \n",
    "3. The GRU unit is able to ignore the input and just copy the previous hidden state. In the beginning of training this might be desireable behavior, since it helps the model learn long range dependencies. You can make the model ignore the input by modifying initial bias values. What bias would you modify and how would you modify it? Again you'll need to refer to the GRU equations:  [GRU](http://lasagne.readthedocs.io/en/latest/modules/layers/recurrent.html#lasagne.layers.GRULayer).\n",
    "\n",
    "4. What is the final validation performance? Why do you think it is not better? Comment on the accuracy for each position in of the output symbols?\n",
    "\n",
    "5. Why do you think the validation performance looks more \"jig-saw\"-like compared to FFNN and CNN models?\n",
    "\n",
    "6. In the example we stack a softmax layer on top of a Recurrent layer. In the code snippet below explain how we can do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs_, seqlen_, numinputs_ = 16, 140, 40\n",
    "l_input_ = lasagne.layers.InputLayer((bs_, seqlen_, numinputs_))\n",
    "l_gru_ = lasagne.layers.GRULayer(l_input_, num_units=10)\n",
    "l_reshape_ = lasagne.layers.ReshapeLayer(l_gru_, (-1, [2])) # the [2] tells lasagne to use the dim of the 2. \n",
    "                                                            # dim of the input here. -1 is a wildcard\n",
    "l_softmax_ = lasagne.layers.DenseLayer(l_reshape_, num_units=11, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "l_softmax_seq_ = lasagne.layers.ReshapeLayer(l_softmax_,(bs_, seqlen_, -1))\n",
    "print \"l_input_\", l_input_.output_shape\n",
    "print \"l_gru_\", l_gru_.output_shape\n",
    "print \"l_reshape_\", l_reshape_.output_shape\n",
    "print \"l_softmax_\", l_softmax_.output_shape\n",
    "print \"l_softmax_seq_\", l_softmax_seq_.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Optional: If you are interested in doing sentiment analysis on tweets, i.e classification as positive or negative. Use RNN to read over the twitter seqeuence and use the last hidden state to do the classification. How can you modify the small network above to only output binary classification? Hints: Look at the SliceLayer or the GRU docs...\n",
    "7. Optional: Bidirectional Encoder, In Lasagne, bidirectional RNNs are implementated by running a forward model and a backward model separately and then concatenating them before parsing them to the next layer. You can experiment with using a different merging layer than concat e.g. sum or multiplication see [lasagne merge layers [lasagne merge layers](http://lasagne.readthedocs.org/en/latest/modules/layers/merge.html).\n",
    "```\n",
    "l_rec_fwd = lasagne.layers.GRULayer(...,backwards=False)\n",
    "l_rec_bwd = lasagne.layers.GRULayer(...,backwards=True)\n",
    "l_rec = lasagne.layers.ConcatLayer([l_rec_fwd, l_rec_bwd], axis=2))\n",
    "```\n",
    "8. Optional: Add support for different lengths of targets (hint: add the target_mask to the cost function and only calculate the cost for the non-masked targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder (LSTM)\n",
    "Selective attention for recurrent neural networks have recently attracted a lot of interest. These methods let the Decoder model selectively focus on which sub-sequence of the encoder sequence it will use for each decoded output symbol. This relieves the encoder from having to compress the input sequence into a fixed size vector representation. Secondly, we can investigate which part of the input that the decoder network emphazises. Below we'll implement an LSTM-decoder with selective attention and show that it significantly improves the performance of the toy translation task.\n",
    "\n",
    "The attention paper is found here: https://arxiv.org/pdf/1409.0473v7.pdf.\n",
    "\n",
    "The principles of the attention model are simple. \n",
    "\n",
    "1. Use the encoder to get the hidden represention $\\{h^1_e, ...h^n_e\\}$ for each position in the input sequence. \n",
    "2. For timestep $t$ in the decoder $m = 1...n$ : $a_m = f(h^m_e, h^d_t)$. Where f is a function returning a scalar value.\n",
    "3. You can then normalize the sequence of scalars $\\{a_1, ... a_n\\}$ to get probablities $\\{p_1, ... p_n\\}$.\n",
    "4. Weigh each $h^e_t$ by its probablity $p_t$ and sum to get $h_{in}$.\n",
    "5. Use $h_{in}$ as an additional input to the decoder. $h_{in}$ is recalculated each time the decoder is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from decoder_attention import LSTMAttentionDecodeFeedbackLayer\n",
    "\n",
    "# you can acces the attetion weights alpha by adding l_dec.alpha \n",
    "# to the output variables in the theano function\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "NUM_UNITS_ENC = 10\n",
    "NUM_UNITS_DEC = 10\n",
    "MAX_DIGITS = 20 \n",
    "MIN_DIGITS = MAX_DIGITS #currently only support for same length outputs - we'll leave it for an exercise to add support for varying length targets\n",
    "NUM_INPUTS = 27\n",
    "NUM_OUTPUTS = 11 #(0-9 + '#')\n",
    "\n",
    "\n",
    "x_sym = T.imatrix()\n",
    "y_sym = T.imatrix()\n",
    "xmask_sym = T.matrix()\n",
    "    \n",
    "\n",
    "#dummy data to test implementation\n",
    "#X = np.random.randint(0,10,size=(BATCH_SIZE,15)).astype('int32')\n",
    "#Xmask = np.ones((BATCH_SIZE,NUM_INPUTS)).astype('float32')\n",
    "\n",
    "l_in = lasagne.layers.InputLayer((None, None))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, NUM_INPUTS, NUM_INPUTS, \n",
    "                                      W=np.eye(NUM_INPUTS,dtype='float32'),\n",
    "                                      name='Embedding')\n",
    "##### ENCODER START #####\n",
    "l_in = lasagne.layers.InputLayer((None, None))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, NUM_INPUTS, NUM_INPUTS, \n",
    "                                      W=np.eye(NUM_INPUTS,dtype='float32'),\n",
    "                                      name='Embedding')\n",
    "#Here we'll remove the trainable parameters from the embeding layer to constrain \n",
    "#it to a simple \"one-hot-encoding\". You can experiment with removing this line\n",
    "l_emb.params[l_emb.W].remove('trainable') \n",
    "print lasagne.layers.get_output(l_emb, inputs={l_in: x_sym}).eval(\n",
    "    {x_sym: X}).shape\n",
    "T.grad(lasagne.layers.get_output(l_emb, inputs={l_in: x_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_emb, trainable=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "l_mask_enc = lasagne.layers.InputLayer((None, None))\n",
    "l_enc = lasagne.layers.GRULayer(l_emb, num_units=NUM_UNITS_ENC, name='GRUEncoder', mask_input=l_mask_enc)\n",
    "print lasagne.layers.get_output(l_enc, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "T.grad(lasagne.layers.get_output(l_enc, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_enc, trainable=True))\n",
    "####END OF ENCODER######\n",
    "\n",
    "\n",
    "####START OF DECODER######\n",
    "#note that the decoder have its own input layer, we'll use that to plug in the output \n",
    "#from the encoder later\n",
    "l_dec = LSTMAttentionDecodeFeedbackLayer(l_enc,\n",
    "                                        num_units=NUM_UNITS_DEC, \n",
    "                                        aln_num_units=20,\n",
    "                                        n_decodesteps=MAX_DIGITS+1,\n",
    "                                        name='LSTMDecoder')\n",
    "print lasagne.layers.get_output(l_dec, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "T.grad(lasagne.layers.get_output(l_dec, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_dec, trainable=True))\n",
    "\n",
    "# We need to do some reshape voodo to connect a softmax layer to the decoder.\n",
    "# See http://lasagne.readthedocs.org/en/latest/modules/layers/recurrent.html#examples \n",
    "l_reshape = lasagne.layers.ReshapeLayer(l_dec, (-1, [2]))\n",
    "l_softmax = lasagne.layers.DenseLayer(l_reshape, num_units=NUM_OUTPUTS, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                                      name='SoftmaxOutput')\n",
    "# print lasagne.layers.get_output(l_softmax, x_sym).eval({x_sym: X}).shape\n",
    "# reshape back to 3d format (here we tied the batch size to the shape of the symbolic variable for X allowing \n",
    "#us to use different batch sizes in the model)\n",
    "l_out = lasagne.layers.ReshapeLayer(l_softmax, (x_sym.shape[0], -1, NUM_OUTPUTS))\n",
    "print lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}, deterministic=False).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "T.grad(lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_dec, trainable=True))\n",
    "\n",
    "print \"\"\n",
    "###END OF DECODER######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate some validation data\n",
    "Xval, Xmask_val, Yval, Ymask_val, text_inputs_val, text_targets_val = \\\n",
    "    get_batch(batch_size=5000, max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get output of encoder using X and Xmask as input\n",
    "output_decoder_train = lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}, \n",
    "                                                 deterministic=False)\n",
    "\n",
    "#cost function\n",
    "total_cost = T.nnet.categorical_crossentropy(\n",
    "    T.reshape(output_decoder_train, (-1, NUM_OUTPUTS)), y_sym.flatten())\n",
    "mean_cost = T.mean(total_cost)\n",
    "#accuracy function\n",
    "acc = T.mean(T.eq(T.argmax(output_decoder_train,axis=-1),y_sym))\n",
    "\n",
    "#Get parameters of both encoder and decoder\n",
    "all_parameters = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "\n",
    "print \"Trainable Model Parameters\"\n",
    "print \"-\"*40\n",
    "for param in all_parameters:\n",
    "    print param, param.get_value().shape\n",
    "print \"-\"*40\n",
    "\n",
    "#add grad clipping to avoid exploding gradients\n",
    "all_grads = [T.clip(g,-3,3) for g in T.grad(mean_cost, all_parameters)]\n",
    "all_grads = lasagne.updates.total_norm_constraint(all_grads,3)\n",
    "\n",
    "#Compile Theano functions\n",
    "updates = lasagne.updates.adam(all_grads, all_parameters, learning_rate=0.005)\n",
    "train_func = theano.function([x_sym, y_sym, xmask_sym], [mean_cost, acc, output_decoder_train], updates=updates)\n",
    "#since we don't have any stochasticity in the network we will just use the training graph without any updates given\n",
    "test_func = theano.function([x_sym, y_sym, xmask_sym], [acc, output_decoder_train, l_dec.alpha])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_interval = 5000\n",
    "samples_to_process = 1.5e5\n",
    "samples_processed = 0\n",
    "val_samples = []\n",
    "costs, accs = [], []\n",
    "plt.figure()\n",
    "try:\n",
    "    while samples_processed < samples_to_process:\n",
    "        inputs, input_masks, targets, target_masks, _, _ = \\\n",
    "            get_batch(batch_size=BATCH_SIZE,max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "        batch_cost, batch_acc, batch_output = train_func(inputs, targets, input_masks)\n",
    "        costs += [batch_cost]\n",
    "        samples_processed += BATCH_SIZE\n",
    "        if samples_processed % val_interval == 0:\n",
    "            #print \"validating\"\n",
    "            val_acc, val_output, alpha = test_func(Xval, Yval, Xmask_val)\n",
    "            val_samples += [samples_processed]\n",
    "            accs += [val_acc]\n",
    "            plt.plot(val_samples,accs)\n",
    "            plt.ylabel('', fontsize=15)\n",
    "            plt.xlabel('Processed samples', fontsize=15)\n",
    "            plt.title('Validation Accuracy', fontsize=20)\n",
    "            plt.grid('on')\n",
    "            plt.savefig(\"out.png\")\n",
    "            display.display(display.Image(filename=\"out.png\"))\n",
    "            display.clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot of validation accuracy for each target position\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(np.mean(np.argmax(val_output,axis=2)==Yval,axis=0))\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.xlabel('Target position', fontsize=15)\n",
    "#plt.title('', fontsize=20)\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "#why do the plot look like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot of average attention weight as a function of the sequence position for each of \n",
    "#the 21 targets in the output sequence i.e. each line is the mean postion of the \n",
    "#attention for each target position.\n",
    "\n",
    "np.mean(alpha,axis=0).shape\n",
    "plt.figure()\n",
    "plt.plot(np.mean(alpha,axis=0).T)\n",
    "plt.ylabel('alpha', fontsize=15)\n",
    "plt.xlabel('Input Sequence position', fontsize=15)\n",
    "plt.title('Alpha weights', fontsize=20)\n",
    "plt.legend(map(str,range(1,22)), bbox_to_anchor=(1.125,1.0), fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Assignments for the attention decoder\n",
    "1. Explain what the alpha weights show. \n",
    "2. Why are the alpha curve for the first digit narrow and peaked while later digits have alpha curves that are wider and less peaked?\n",
    "3. Why is attention a good idea for this problem? Can you think of other problems where attention is a good choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
